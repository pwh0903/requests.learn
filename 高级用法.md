## Session对象
Session对象允许在多个请求间保持某些参数和cookies,使用urllib3连接池.
所以如果你向同一主机发起多个请求,底层的TCP连接会被复用,大大提高性能.

Session对象有所有的HTTP方法
```python
url = ''http://httpbin.org/cookies/set/sessioncookie/123456789''
s = requests.Session()
r = s.get(url)
print(r.text)

# 设置session中的属性
s.auth = ('username', 'password')
s.header.update({'x-text': 'True'})
# 传递给request方法的字典都会和session层设置的值合并,如有重复,method层的会覆盖session层的值
# method层的参数只对当前method有效 
s.get(url, headers={'x-text2': 'True'})

# 在method层中设置None值可以忽略session中设置的值
s.get(url, headers={'x-text1': None})
```

Sessions可以用作上下文管理器
```python
# 在with语句结束后session立即关闭
with requests.Session() as s:
    s.get(url)
```


## 请求和响应对象
当调用requests.get()时,发生两件事
1.构建一个Request对象发送给服务器,用来请求资源
2.Requests接受到响应时产生一个response对象,包含了所有服务器返回的信息和1中创建的request对象
```python
r = requests.get(url)
print(r.headers)
print(r.request.heads)
```


## 准备请求
```python
from requests import Request, Session

s = Session()

req = Request('POST', url, data=data, headers=headers)
prepped = req.prepare()
 
perpped.body = "No, I want exactly this as the body."
del prepped.headers['content-type']

resp = s.send(prepped, stream=stream, verify=verify, proxies=proxies, cert=cert, timeout=timeout)
print(resp.status_code)
```


## SSL Cert Verification
Requests在https请求时检查SSL证书,默认开启,如果不能检查,抛出SSLError
```python
requests.get(url, verify='/path/to/certfile')

# session
s = requests.Session()
s.verify = '/path/to/certfile'

# 不开启SSL认证
requests.get(url, verify=False)

# 启用客户端认证,指定本地认证文件(不能是加密过的)
requests.get(url, cert=('/path/client.key', '/path/client.cert'))

s = requests.Session()
s.cert = '/path/client.cert'
s.key = '/path/client.key'
```
通过REQUESTS_CA_BUNDLE环境变量指定信任的CAs列表


## Body Content Workflow
默认情况下,当你产生了一个请求,响应的body立即被下载.
你可以使用sream参数override这个行为,延迟下载response body直到你访问Response.content属性
```python
# 只有响应头被下载,连接保持,让我们可以根据条件检索内容
tarball_url = 'https://github.com/kennethreitz/requests/tarball/master'
r = requests.get(tarball_url, stream=True)
if int(r.headers['content-length']) < TOO_LONG:
    content = r.content
```

除非得到了所有的data或调用`Response.close`,连接不被释放
如果你只需要部分内容,可以考虑使用`contextlib.closing`
```python
from contextlib import closing
with closing(requests.get(url, stream=True)) as r:
    # Do something    
```


# Keep-Alive
session中的请求会自动复用合适的连接
注意,只有在body data被全部读取后连接才会被释放回连接池以供复用,确保`stream=False`或完整的读完`Response`对象的`content`


## Streaming Uploads
允许发送大文件而不用将它们读入内存
```python
with open('massive-body', 'rb') as f:
    requests.post(url, data=f)
```


## Chunk-Encoded Requests


## POST Multiple Multipart-Encoded Files


## Event Hooks


## Custom Authentication


## Streaming Requests


## 代理
通过请求的`proxies`参数设置代理
```python
import requests

proxies = {
    'http': 'http://10.10.1.10:3128',
    'https': 'http://10.10.1.10:1080',
    'http': 'http://user:pass@10.10.1.10:3128/'
}
requests.get(url, proxies=proxies)

# 代理配对
proxies = {'http://10.20.1.128': 'http://10.10.1.10:5323'}
```
设置环境变量`HTTP_PROXY`和`HTTPS_PROXY`,指定代理
```
export HTTP_PROXY="http://10.10.1.10:3128"
export HTTPS_PROXY="http://10.10.1.10:1080"
```

# SOCKS
```python
pip install requests[socks]

proxies = {
    'http': 'socks5://user:pass@host:port',
    'https': 'socks5://user:pass@host:port',
```


## Compliance


## HTTP Verbs


## Custom Verbs
eg. MKCOL方法
```python
r = requests.request('MKCOL', url, data=data)
r.status_code
```
